
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Econometrics I</title><meta name="generator" content="MATLAB 9.9"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2022-02-04"><meta name="DC.source" content="s3.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; }

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
span.typesection { color:#A0522D }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Econometrics I</h1><pre>TA Christian Alem&aacute;n</pre><p><b>Session 3: Friday 4, February 2022</b></p><p><b>Activity 1: Random Sampling</b></p><p>Simulate a Population</p><p><img src="s3_eq17306737469895591427.png" alt="$x\sim\mathcal{N}(\mu,\sigma^{2})$"></p><pre class="codeinput"><span class="comment">% Housekeeping</span>
clear <span class="string">all</span>
close <span class="string">all</span>
clc
<span class="comment">%</span>
<span class="comment">% Begin Script</span>
rng(1234)                 <span class="comment">% Set seed for reproductivity</span>
<span class="comment">%</span>
<span class="comment">% Simulate the Universe</span>
<span class="comment">% Plot options</span>
par.num_bins  = 50;
opt.norm_type = {<span class="string">'count'</span>,<span class="string">'pdf'</span>};    <span class="comment">% Normalization type</span>
opt.sel_norm  = 2;                  <span class="comment">% 1: count 2: pdf</span>


par.N  = 1000000;         <span class="comment">% Our Universe</span>
par.NS = 50;             <span class="comment">% Size of our sample</span>
par.MS = 1000;           <span class="comment">% Number of samples</span>
par.sigma = [0.1,0.5];
par.mu    = 4;
vars.x_vec = NaN(par.N,2);
vars.x_sample = NaN(par.NS,par.MS,2);
vars.x_mean   = NaN(par.MS,2);
vars.y_sample = NaN(par.NS,par.MS,2);
vars.y_mean   = NaN(1,par.MS,2);
<span class="keyword">for</span> i = 1:2
</pre><pre class="codeinput">    vars.x_vec(:,i) =  par.mu + par.sigma(i).*randn(par.N,1);
</pre><p>With Loop: Generate NS number of samples from the universe.</p><pre class="codeinput">    <span class="keyword">for</span> j = 1:par.MS
        vars.x_sample(:,j,i) = randsample(vars.x_vec(:,i),par.NS);
        vars.x_mean(j,i) = mean(vars.x_sample(:,j,i));
    <span class="keyword">end</span>
</pre><p>Without a loop Purely for Montecarlo Purposes:</p><pre class="codeinput">    vars.y_sample(:,:,i) =  par.mu + par.sigma(i).*randn(par.NS,par.MS);
    vars.y_mean(1,:,i) = mean(vars.y_sample(:,:,i),1);
</pre><pre class="codeinput"><span class="keyword">end</span>
</pre><p>Plot the Distribution of Means and the true mean</p><pre class="codeinput">figure(1)
subplot(2,1,1)
histogram(vars.x_mean(:,1),par.num_bins,<span class="string">'Normalization'</span>,opt.norm_type{opt.sel_norm});
xline(par.mu,<span class="string">'g-'</span>,<span class="string">'linewidth'</span>,2)
xline(mean(vars.x_mean(:,1)),<span class="string">'r-'</span>,<span class="string">'linewidth'</span>,2)
title([<span class="string">'$\sigma^{2} = $'</span>,num2str(par.sigma(1)^2)],<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'fontsize'</span>,17)
xlim([3.7,4.3])
legend({<span class="string">'Dist of the Mean'</span>,<span class="string">'True'</span>,<span class="string">'Estimated'</span>})
ylabel(opt.norm_type{opt.sel_norm})
subplot(2,1,2)
histogram(vars.x_mean(:,2),par.num_bins,<span class="string">'Normalization'</span>,opt.norm_type{opt.sel_norm});
xline(par.mu,<span class="string">'g-'</span>,<span class="string">'linewidth'</span>,2)
xline(mean(vars.x_mean(:,2)),<span class="string">'r-'</span>,<span class="string">'linewidth'</span>,2)
title([<span class="string">'$\sigma^{2} = $'</span>,num2str(par.sigma(2)^2)],<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'fontsize'</span>,17)
xlim([3.7,4.3])
legend({<span class="string">'Dist of the Mean'</span>,<span class="string">'True'</span>,<span class="string">'Estimated'</span>})
ylabel(opt.norm_type{opt.sel_norm})
</pre><img vspace="5" hspace="5" src="s3_01.png" alt=""> <p>Do the same for the generalized pareto:</p><pre class="codeinput">rng(567)                 <span class="comment">% Set seed for reproductivity</span>

par.sigma     = 0.1;  <span class="comment">% Scale</span>
par.k         = 0.8;  <span class="comment">% Index, shape</span>
par.theta     = 0;  <span class="comment">% Threshold, location</span>
vars.x_vec     = gprnd(par.k,par.sigma,par.theta,par.N,1);
par.MS        = 2000;
par.NS        = 200;             <span class="comment">% Size of our sample</span>
par.mu_A        = par.theta+(2^(par.k)-1).*par.sigma./par.k;
par.mu_B        = par.theta+par.sigma./(1-par.k);
<span class="comment">% Initialize Matrix Holders</span>
vars.x_sample = NaN(par.NS,par.MS);
vars.x_mean   = NaN(1,par.MS);
vars.x_median   = NaN(1,par.MS);
<span class="comment">% Plot the histogram of the distribution of the Universe</span>
I = vars.x_vec&gt;4;
figure(2)
hold <span class="string">on</span>
histogram(vars.x_vec(not(I)),par.num_bins,<span class="string">'Normalization'</span>,opt.norm_type{opt.sel_norm});
legend(<span class="string">'Distribution of the Universe'</span>)
ylabel(opt.norm_type{opt.sel_norm})


<span class="keyword">for</span> j = 1:par.MS
    vars.x_sample(:,j) = randsample(vars.x_vec,par.NS);
    vars.x_median(j) = median(vars.x_sample(:,j));
    vars.x_mean(j) = mean(vars.x_sample(:,j));
<span class="keyword">end</span>
</pre><img vspace="5" hspace="5" src="s3_02.png" alt=""> <p>Plot the Distribution of Medians</p><pre class="codeinput">figure(3)
<span class="comment">%histogram(vars.x_mean,par.num_bins,'Normalization',opt.norm_type{opt.sel_norm});</span>
<span class="comment">%xline(mean(vars.x_mean),'r-','linewidth',2)</span>
<span class="comment">%xline(par.mu_B,'g-','linewidth',2)</span>
histogram(vars.x_median,par.num_bins,<span class="string">'Normalization'</span>,opt.norm_type{opt.sel_norm});
xline(par.mu_A,<span class="string">'g-'</span>,<span class="string">'linewidth'</span>,2)
xline(mean(vars.x_median),<span class="string">'r-'</span>,<span class="string">'linewidth'</span>,2)
legend({<span class="string">'Dist of the Median'</span>,<span class="string">'True'</span>,<span class="string">'Estimated'</span>})
ylabel(opt.norm_type{opt.sel_norm})
</pre><img vspace="5" hspace="5" src="s3_03.png" alt=""> <p><b>Activity 2: Backing out Residuals</b></p><p><img src="s3_eq16608997210749585985.png" alt="$y = \beta_{0} + \beta_{1} x + e$">  Where   <img src="s3_eq14637684342522431612.png" alt="$\,\,\,e\sim \mathcal{N}(0,\sigma^{2})$"></p><pre class="codeinput"><span class="comment">%</span>
rng(4567)
par.n = 500;
<span class="comment">% Simulate x</span>
par.mean_x1 = 4;
par.variance_x = 2;
par.variance_e = [0.1,0.3,0.8];
x = par.mean_x1 +sqrt(par.variance_x).*randn(par.n,1);
<span class="comment">% Model coefficients:</span>
par.beta0 = 2;
par.beta1 = 0.5;
<span class="comment">% Simulate error</span>
err = NaN(par.n,3);
y   = NaN(par.n,3);
<span class="keyword">for</span> i = 1:3
    err(:,i) = 0 + sqrt(par.variance_e(i)).*randn(par.n,1);
    <span class="comment">% Simulate Data Generating Process:</span>
    y(:,i) = par.beta0 + par.beta1.*x +err(:,i);
    <span class="comment">% Estimate the OLS and back out the Residuals</span>
    <span class="keyword">if</span> i ==1
        vars_1 = ols_esti(y(:,i),[ones(par.n,1) x]);
    <span class="keyword">elseif</span> i ==2
        vars_2 = ols_esti(y(:,i),[ones(par.n,1) x]);
    <span class="keyword">else</span>
        vars_3 = ols_esti(y(:,i),[ones(par.n,1) x]);
    <span class="keyword">end</span>
<span class="keyword">end</span>

figure(4)
hold <span class="string">on</span>
grid <span class="string">on</span>
plot(x,y(:,1),<span class="string">'kx'</span>)
plot(x,vars_1.y_hat,<span class="string">'b-'</span>,<span class="string">'linewidth'</span>,1.1)
ylim([0,8])
xlabel(<span class="string">'$x$'</span>,<span class="string">'fontsize'</span>,17,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>)
ylabel(<span class="string">'$y$'</span>,<span class="string">'fontsize'</span>,17,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>)
title([<span class="string">'$\sigma^{2} = $ '</span>,num2str(par.variance_e(1))],<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'fontsize'</span>,17)
figure(5)
hold <span class="string">on</span>
grid <span class="string">on</span>
plot(x,y(:,2),<span class="string">'kx'</span>)
plot(x,vars_2.y_hat,<span class="string">'b-'</span>,<span class="string">'linewidth'</span>,1.1)
ylim([0,8])
xlabel(<span class="string">'$x$'</span>,<span class="string">'fontsize'</span>,17,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>)
ylabel(<span class="string">'$y$'</span>,<span class="string">'fontsize'</span>,17,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>)
title([<span class="string">'$\sigma^{2} = $'</span>,num2str(par.variance_e(2))],<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'fontsize'</span>,17)
figure(6)
hold <span class="string">on</span>
grid <span class="string">on</span>
plot(x,y(:,3),<span class="string">'kx'</span>)
plot(x,vars_3.y_hat,<span class="string">'b-'</span>,<span class="string">'linewidth'</span>,1.1)
ylim([0,8])
xlabel(<span class="string">'$x$'</span>,<span class="string">'fontsize'</span>,17,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>)
ylabel(<span class="string">'$y$'</span>,<span class="string">'fontsize'</span>,17,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>)
title([<span class="string">'$\sigma^{2} = $'</span>,num2str(par.variance_e(3))],<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'fontsize'</span>,17)
</pre><img vspace="5" hspace="5" src="s3_04.png" alt=""> <img vspace="5" hspace="5" src="s3_05.png" alt=""> <img vspace="5" hspace="5" src="s3_06.png" alt=""> <pre>Plot the distrobution of the residuals</pre><pre class="codeinput">figure(7)
subplot(3,1,1)
hold <span class="string">on</span>
grid <span class="string">on</span>
histogram(vars_1.e_hat,par.num_bins,<span class="string">'Normalization'</span>,opt.norm_type{opt.sel_norm});
ylabel(<span class="string">'Density'</span>,<span class="string">'fontsize'</span>,17,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>)
xlabel(<span class="string">'$\hat{e}$'</span>,<span class="string">'fontsize'</span>,17,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>)
title([<span class="string">'$\sigma^{2}$ = '</span>,num2str(par.variance_e(1)),<span class="string">'  $\hat{\sigma}^{2}$ = '</span>,num2str(var(vars_1.e_hat))],<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'fontsize'</span>,17)
xlim([-1.6,1.6])
subplot(3,1,2)
hold <span class="string">on</span>
grid <span class="string">on</span>
histogram(vars_2.e_hat,par.num_bins,<span class="string">'Normalization'</span>,opt.norm_type{opt.sel_norm});
ylabel(<span class="string">'Density'</span>,<span class="string">'fontsize'</span>,17,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>)
xlabel(<span class="string">'$\hat{e}$'</span>,<span class="string">'fontsize'</span>,17,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>)
title([<span class="string">'$\sigma^{2}$ = '</span>,num2str(par.variance_e(2)),<span class="string">'  $\hat{\sigma}^{2}$ = '</span>,num2str(var(vars_2.e_hat))],<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'fontsize'</span>,17)
xlim([-1.6,1.6])
subplot(3,1,3)
hold <span class="string">on</span>
grid <span class="string">on</span>
histogram(vars_3.e_hat,par.num_bins,<span class="string">'Normalization'</span>,opt.norm_type{opt.sel_norm});
ylabel(<span class="string">'Density'</span>,<span class="string">'fontsize'</span>,17,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>)
xlabel(<span class="string">'$\hat{e}$'</span>,<span class="string">'fontsize'</span>,17,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>)
title([<span class="string">'$\sigma^{2}$ = '</span>,num2str(par.variance_e(3)),<span class="string">'  $\hat{\sigma}^{2}$ = '</span>,num2str(var(vars_3.e_hat))],<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'fontsize'</span>,17)
xlim([-3,3])
</pre><img vspace="5" hspace="5" src="s3_07.png" alt=""> <p><b>Activity 3: Understanding Collinearity</b></p><p><img src="s3_eq13795736703085274674.png" alt="$y = \beta_{0} + \beta_{1} x_{1} + \beta_{2} x_{2} + \epsilon$">  Where   <img src="s3_eq13784265295906457464.png" alt="$\,\,\,\epsilon\sim \mathcal{N}(0,\sigma^{2}_{\epsilon})$"></p><p>and <img src="s3_eq02141242292923430149.png" alt="$X = (x_{1}, x_{2})'$"> where <img src="s3_eq03177071793748181258.png" alt="$X \sim \mathcal{N}(\mu,\Sigma)$"> with <img src="s3_eq01820451864318463891.png" alt="$\Sigma = \left[\begin{array}{cc}\sigma^{2}_{x_{1}} &amp; \rho\sigma_{x_{1}}\sigma_{x_{2}} \\ \rho\sigma_{x_{1}}\sigma_{x_{2}} &amp; \sigma_{x_{2}}^{2} \end{array}\right]$"></p><p>Some Parameters we can play with:</p><div><ol><li>Number of Samples</li><li>Variance of the error <img src="s3_eq08386105417946692556.png" alt="$\sigma^{2}_{\epsilon}$"></li><li>Variance ofx <img src="s3_eq17462334479960354975.png" alt="$\sigma^{2}_{x_{1}}$"></li><li>Correlation <img src="s3_eq11905270608999804013.png" alt="$\rho$"> between <img src="s3_eq15221720655928888702.png" alt="$x_{1}$"> and <img src="s3_eq08159277116585170228.png" alt="$x_{2}$"></li></ol></div><pre class="codeinput">par.names = {<span class="string">'$\sigma^{2}_{\epsilon}$ '</span>,<span class="string">'$\sigma^{2}_{x_{1}}$ '</span>,<span class="string">'$\rho$ '</span>};
<span class="comment">% Data Generating process values:</span>
grids.sigma_e  = [0.01,0.3,0.6,1,2.6,3];
grids.sigma_x1 = [0.01,0.1,0.8,1.6,2,2.5];
grids.rho      = [0,0.6,0.9,0.95,0.99,1];

<span class="comment">% Default Values:</span>


par.n  = 100;       <span class="comment">% Sample size</span>
par.ns = 1000;      <span class="comment">% Number of Montecarlo Samples</span>
<span class="comment">% Simulate x</span>
par.mean_x1 = 20;
par.mean_x2 = 27;
par.variance_x2 = 1.4;
<span class="comment">% Model coefficients:</span>
par.beta0 = 2;
par.beta1 = 0.3;
par.beta2 = 1.5;
<span class="comment">% Simulate error</span>
err = NaN(par.n,par.ns);
y   = NaN(par.n,par.ns);
X   = NaN(par.n,2,par.ns);
SE_beta_hat = NaN(par.ns,1);
beta1_hat   = NaN(par.ns,1);
mu_beta     = NaN(6,3);
mu_SEbeta   = NaN(6,3);
<span class="comment">% Simulate Data Generating Process:</span>
par. variance_e  = grids.sigma_e(2);
par. variance_x1 = grids.sigma_x1(3);
par. rho         = grids.rho(1);


<span class="keyword">for</span> i = 1:3
    it = 0;
    <span class="keyword">for</span> ii = 1:6
        <span class="comment">% Defaults:</span>

        <span class="keyword">if</span> i ==1
            par.varianve_e = grids.sigma_e(ii);
            par.name_val = par.varianve_e;
        <span class="keyword">elseif</span> i ==2
            par.variance_x1 = grids.sigma_x1(ii);
            par.name_val = par.variance_x1;
        <span class="keyword">elseif</span> i ==3
            par.rho = grids.rho(ii);
            par.name_val = par.rho;
        <span class="keyword">end</span>
        <span class="comment">% Simulate the Correlated Variables</span>

        par.big_sigma = [par.variance_x1,sqrt(par.variance_x1)*sqrt(par.variance_x2)*par.rho;sqrt(par.variance_x1)*sqrt(par.variance_x2)*par.rho,par.variance_x2];
        <span class="keyword">for</span> oo = 1:par.ns
            <span class="comment">% Generate the data</span>
            rng((i*100000)+(ii*10000)+oo)
            err(:,oo) = 0 + sqrt(par.variance_e).*randn(par.n,1);
            X(:,:,oo) = mvnrnd([par.mean_x1,par.mean_x2],par.big_sigma,par.n);
            y(:,oo) = par.beta0 + par.beta1.*X(:,1,oo)+par.beta2.*X(:,2,oo) +err(:,oo);
            <span class="comment">% Estimate OLS</span>
            <span class="keyword">try</span>
                vars = ols_esti(y(:,oo),[ones(par.n,1) X(:,:,oo)]);
                SE_beta_hat(oo,1) = vars.SEbeta_hat(2);
                beta1_hat(oo,1)   = vars.beta_hat(2);
            <span class="keyword">catch</span>
                <span class="keyword">if</span> oo ==1
                disp(<span class="string">'Perfect Colinearity, check your variables!'</span>)
                <span class="keyword">end</span>
                SE_beta_hat = NaN(par.ns,1);
                beta1_hat   = NaN(par.ns,1);
            <span class="keyword">end</span>
            <span class="comment">% Extract Values</span>

        <span class="keyword">end</span>

        mu_beta(ii,i)   =  mean(beta1_hat);
        mu_SEbeta(ii,i) =  mean(SE_beta_hat);
        <span class="comment">% Compute and save the mean of the OLS estimator</span>
        <span class="comment">% Plot the Histograms</span>
        <span class="keyword">if</span> ii == 1|| ii == 3|| ii ==5
        it = it+1;
        figure(10+i)
        subplot(3,1,it)
        hold <span class="string">on</span>
        histogram(beta1_hat,par.num_bins,<span class="string">'Normalization'</span>,opt.norm_type{opt.sel_norm});
        xline(par.beta1,<span class="string">'g-'</span>,<span class="string">'linewidth'</span>,2)
        xline(mean(mu_beta(ii,i)),<span class="string">'r-'</span>,<span class="string">'linewidth'</span>,2)
        ylabel(<span class="string">'Density'</span>,<span class="string">'fontsize'</span>,13,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>)
        xlabel(<span class="string">'$\hat{\beta}$'</span>,<span class="string">'fontsize'</span>,13,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>)
        title([par.names{i},<span class="string">' = '</span>,num2str(par.name_val)],<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'fontsize'</span>,15)

        <span class="keyword">end</span>
        par. variance_e  = grids.sigma_e(2);
        par. variance_x1 = grids.sigma_x1(3);
        par. rho         = grids.rho(1);
    <span class="keyword">end</span>

<span class="keyword">end</span>
</pre><pre class="codeoutput">Perfect Colinearity, check your variables!
</pre><img vspace="5" hspace="5" src="s3_08.png" alt=""> <img vspace="5" hspace="5" src="s3_09.png" alt=""> <img vspace="5" hspace="5" src="s3_10.png" alt=""> <p>The consequences of collinearity</p><pre class="codeinput">figure(33)
hold <span class="string">on</span>
grid <span class="string">on</span>
plot(grids.rho,mu_beta(:,3),<span class="string">'ko-'</span>,<span class="string">'MarkerFaceColor'</span>,<span class="string">'k'</span>,<span class="string">'linewidth'</span>,1.2)
plot(grids.rho,mu_SEbeta(:,3),<span class="string">'mo-'</span>,<span class="string">'MarkerFaceColor'</span>,<span class="string">'m'</span>,<span class="string">'linewidth'</span>,1.2)
yline(par.beta1,<span class="string">'r'</span>)
ylabel(<span class="string">'$\beta_{1}$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'fontsize'</span>,17)
xlabel(<span class="string">'$\rho$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'fontsize'</span>,17)
legend({<span class="string">'$E(\hat{\beta_{1}})$'</span>,<span class="string">'$E(SEbeta_{1})$'</span>,<span class="string">'$\beta_{1}$'</span>},<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'location'</span>,<span class="string">'best'</span>)
title(<span class="string">'Consequences of Collinearity'</span>)
</pre><img vspace="5" hspace="5" src="s3_11.png" alt=""> <p>Consequences of not having enough variation for identification</p><pre class="codeinput">figure(32)
hold <span class="string">on</span>
grid <span class="string">on</span>
plot(grids.sigma_x1,mu_beta(:,2),<span class="string">'ko-'</span>,<span class="string">'MarkerFaceColor'</span>,<span class="string">'k'</span>,<span class="string">'linewidth'</span>,1.2)
plot(grids.sigma_x1,mu_SEbeta(:,2),<span class="string">'mo-'</span>,<span class="string">'MarkerFaceColor'</span>,<span class="string">'m'</span>,<span class="string">'linewidth'</span>,1.2)
yline(par.beta1,<span class="string">'r'</span>)
ylabel(<span class="string">'$\beta_{1}$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'fontsize'</span>,17)
xlabel(<span class="string">'$\sigma^{2}_{x1}$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'fontsize'</span>,17)
legend({<span class="string">'$E(\hat{\beta_{1}})$'</span>,<span class="string">'$E(SEbeta_{1})$'</span>,<span class="string">'$\beta_{1}$'</span>},<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'location'</span>,<span class="string">'best'</span>)
title(<span class="string">'Consequences of Low Variance for Identification'</span>)
</pre><img vspace="5" hspace="5" src="s3_12.png" alt=""> <p>No consequences of having having a larger variance of the error</p><pre class="codeinput">figure(31)
hold <span class="string">on</span>
grid <span class="string">on</span>
plot(grids.sigma_e,mu_beta(:,1),<span class="string">'ko-'</span>,<span class="string">'MarkerFaceColor'</span>,<span class="string">'k'</span>,<span class="string">'linewidth'</span>,1.2)
plot(grids.sigma_e,mu_SEbeta(:,1),<span class="string">'mo-'</span>,<span class="string">'MarkerFaceColor'</span>,<span class="string">'m'</span>,<span class="string">'linewidth'</span>,1.2)
yline(par.beta1,<span class="string">'r'</span>)
ylabel(<span class="string">'$\beta_{1}$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'fontsize'</span>,17)
xlabel(<span class="string">'$\sigma^{2}_{\epsilon}$'</span>,<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'fontsize'</span>,17)
legend({<span class="string">'$E(\hat{\beta_{1}})$'</span>,<span class="string">'$E(SEbeta_{1})$'</span>,<span class="string">'$\beta_{1}$'</span>},<span class="string">'interpreter'</span>,<span class="string">'latex'</span>,<span class="string">'location'</span>,<span class="string">'best'</span>)
title(<span class="string">'No Consequence of Larger measurment error'</span>)
</pre><img vspace="5" hspace="5" src="s3_13.png" alt=""> <pre class="codeinput"><span class="comment">%-------------------------------------------------------------------------</span>
<span class="comment">% OLS</span>
<span class="keyword">function</span> [vars] = ols_esti(y,X)
<span class="comment">%{
</span><span class="comment">This function computes the Least Squares Estimate
</span><span class="comment">Input:
</span><span class="comment">y: Dependent Variable    (N,1)
</span><span class="comment">X: Independent Variables (N,K)
</span><span class="comment">Output:
</span><span class="comment">Many stuff you saw in class.
</span><span class="comment">
</span><span class="comment">%}
</span>[par.Nx,par.K] 	= size(X);   <span class="comment">% N=no.obs; K=no.regressors</span>
[par.Ny] 	= size(y,1); <span class="comment">%</span>

<span class="keyword">if</span> par.Ny~=par.Nx
    error(<span class="string">'X and y do not have same length'</span>)
<span class="keyword">end</span>
I = rank(X'*X) == par.K;
<span class="keyword">if</span> I ==0
    error(<span class="string">'Not complete Rank, Perfect Colinearity'</span>)
<span class="keyword">end</span>
par.N = par.Nx; <span class="comment">% Save number of regressots</span>

vars.beta_hat  = X\y;
<span class="comment">% Coefficients:</span>
vars.beta_hat_alt  = inv(X'*X)*(X'*y);
<span class="comment">% Predicted values:</span>
vars.y_hat 	= X*vars.beta_hat;
<span class="comment">% Residuals:</span>
vars.e_hat 	= y-X*vars.beta_hat;
<span class="comment">% Total Variation of the dependent variable</span>
vars.SST 	= (y - mean(y))'*(y - mean(y));
<span class="comment">% (SSE) Sum Squared Residuals</span>
vars.SSE	= vars.e_hat'*vars.e_hat;
<span class="comment">% SSR/SST or "r-squared" is the ratio of the variation in y explained by the model and the total variation of y</span>
vars.R2 	= 1 - (vars.SSE/vars.SST);
<span class="comment">% Adjusted "r-squared".</span>
vars.R2A 	= 1 - (vars.SSE/(par.N-par.K))/(vars.SST/(par.N-1));

vars.sigma2_hat = vars.SSE/(par.N-par.K);

<span class="comment">%Variance of estimator:</span>
vars.var_covar  = vars.sigma2_hat*inv(X'*X);
vars.SEbeta_hat = sqrt(diag(vars.var_covar));

<span class="keyword">end</span>
</pre><p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2020b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Econometrics I 
%  TA Christian AlemÃ¡n
% 
% *Session 1: Friday 4, February 2022*
% 
% *Activity 1: Random Sampling* 
% 
% Simulate a Population 
%
% $x\sim\mathcal{N}(\mu,\sigma^{2})$

% Housekeeping
clear all
close all
clc
%
% Begin Script
rng(1234)                 % Set seed for reproductivity
% 
% Simulate the Universe 
% Plot options
par.num_bins  = 50;
opt.norm_type = {'count','pdf'};    % Normalization type
opt.sel_norm  = 2;                  % 1: count 2: pdf


par.N  = 1000000;         % Our Universe
par.NS = 50;             % Size of our sample
par.MS = 1000;           % Number of samples
par.sigma = [0.1,0.5];
par.mu    = 4;
vars.x_vec = NaN(par.N,2);
vars.x_sample = NaN(par.NS,par.MS,2);
vars.x_mean   = NaN(par.MS,2);
vars.y_sample = NaN(par.NS,par.MS,2);
vars.y_mean   = NaN(1,par.MS,2);
for i = 1:2
    vars.x_vec(:,i) =  par.mu + par.sigma(i).*randn(par.N,1);
    %%
    % With Loop:
    % Generate NS number of samples from the universe.
    for j = 1:par.MS
        vars.x_sample(:,j,i) = randsample(vars.x_vec(:,i),par.NS); 
        vars.x_mean(j,i) = mean(vars.x_sample(:,j,i));
    end
    
    %%
    % Without a loop
    % Purely for Montecarlo Purposes:
    vars.y_sample(:,:,i) =  par.mu + par.sigma(i).*randn(par.NS,par.MS);
    vars.y_mean(1,:,i) = mean(vars.y_sample(:,:,i),1); 
end

%%
% Plot the Distribution of Means and the true mean

figure(1)
subplot(2,1,1)
histogram(vars.x_mean(:,1),par.num_bins,'Normalization',opt.norm_type{opt.sel_norm}); 
xline(par.mu,'g-','linewidth',2)
xline(mean(vars.x_mean(:,1)),'r-','linewidth',2)
title(['$\sigma^{2} = $',num2str(par.sigma(1)^2)],'interpreter','latex','fontsize',17)
xlim([3.7,4.3])
legend({'Dist of the Mean','True','Estimated'})
ylabel(opt.norm_type{opt.sel_norm})
subplot(2,1,2)
histogram(vars.x_mean(:,2),par.num_bins,'Normalization',opt.norm_type{opt.sel_norm}); 
xline(par.mu,'g-','linewidth',2)
xline(mean(vars.x_mean(:,2)),'r-','linewidth',2)
title(['$\sigma^{2} = $',num2str(par.sigma(2)^2)],'interpreter','latex','fontsize',17)
xlim([3.7,4.3])
legend({'Dist of the Mean','True','Estimated'})
ylabel(opt.norm_type{opt.sel_norm})


%%
% Do the same for the generalized pareto:

rng(567)                 % Set seed for reproductivity

par.sigma     = 0.1;  % Scale
par.k         = 0.8;  % Index, shape
par.theta     = 0;  % Threshold, location
vars.x_vec     = gprnd(par.k,par.sigma,par.theta,par.N,1);
par.MS        = 2000;
par.NS        = 200;             % Size of our sample
par.mu_A        = par.theta+(2^(par.k)-1).*par.sigma./par.k; 
par.mu_B        = par.theta+par.sigma./(1-par.k); 
% Initialize Matrix Holders
vars.x_sample = NaN(par.NS,par.MS);
vars.x_mean   = NaN(1,par.MS);
vars.x_median   = NaN(1,par.MS);
% Plot the histogram of the distribution of the Universe
I = vars.x_vec>4;
figure(2)
hold on
histogram(vars.x_vec(not(I)),par.num_bins,'Normalization',opt.norm_type{opt.sel_norm});  
legend('Distribution of the Universe')
ylabel(opt.norm_type{opt.sel_norm})


for j = 1:par.MS
    vars.x_sample(:,j) = randsample(vars.x_vec,par.NS); 
    vars.x_median(j) = median(vars.x_sample(:,j));
    vars.x_mean(j) = mean(vars.x_sample(:,j));
end

%%
% Plot the Distribution of Medians
figure(3)
%histogram(vars.x_mean,par.num_bins,'Normalization',opt.norm_type{opt.sel_norm}); 
%xline(mean(vars.x_mean),'r-','linewidth',2)
%xline(par.mu_B,'g-','linewidth',2)
histogram(vars.x_median,par.num_bins,'Normalization',opt.norm_type{opt.sel_norm}); 
xline(par.mu_A,'g-','linewidth',2)
xline(mean(vars.x_median),'r-','linewidth',2)
legend({'Dist of the Median','True','Estimated'})
ylabel(opt.norm_type{opt.sel_norm})


%%
% *Activity 2: Backing out Residuals*
% 
% $y = \beta_{0} + \beta_{1} x + e$  Where   $\,\,\,e\sim \mathcal{N}(0,\sigma^{2})$

% 
rng(4567) 
par.n = 500;
% Simulate x
par.mean_x1 = 4;
par.variance_x = 2;
par.variance_e = [0.1,0.3,0.8];
x = par.mean_x1 +sqrt(par.variance_x).*randn(par.n,1);
% Model coefficients:
par.beta0 = 2;
par.beta1 = 0.5;
% Simulate error
err = NaN(par.n,3);
y   = NaN(par.n,3);
for i = 1:3
    err(:,i) = 0 + sqrt(par.variance_e(i)).*randn(par.n,1); 
    % Simulate Data Generating Process:
    y(:,i) = par.beta0 + par.beta1.*x +err(:,i);
    % Estimate the OLS and back out the Residuals
    if i ==1
        vars_1 = ols_esti(y(:,i),[ones(par.n,1) x]);
    elseif i ==2
        vars_2 = ols_esti(y(:,i),[ones(par.n,1) x]);
    else
        vars_3 = ols_esti(y(:,i),[ones(par.n,1) x]);
    end
end

figure(4)
hold on
grid on
plot(x,y(:,1),'kx')
plot(x,vars_1.y_hat,'b-','linewidth',1.1)
ylim([0,8])
xlabel('$x$','fontsize',17,'interpreter','latex')
ylabel('$y$','fontsize',17,'interpreter','latex')
title(['$\sigma^{2} = $ ',num2str(par.variance_e(1))],'interpreter','latex','fontsize',17)
figure(5)
hold on
grid on
plot(x,y(:,2),'kx')
plot(x,vars_2.y_hat,'b-','linewidth',1.1)
ylim([0,8])
xlabel('$x$','fontsize',17,'interpreter','latex')
ylabel('$y$','fontsize',17,'interpreter','latex')
title(['$\sigma^{2} = $',num2str(par.variance_e(2))],'interpreter','latex','fontsize',17)
figure(6)
hold on
grid on
plot(x,y(:,3),'kx')
plot(x,vars_3.y_hat,'b-','linewidth',1.1)
ylim([0,8])
xlabel('$x$','fontsize',17,'interpreter','latex')
ylabel('$y$','fontsize',17,'interpreter','latex')
title(['$\sigma^{2} = $',num2str(par.variance_e(3))],'interpreter','latex','fontsize',17)

%%
%  Plot the distrobution of the residuals 

figure(7)
subplot(3,1,1)
hold on
grid on
histogram(vars_1.e_hat,par.num_bins,'Normalization',opt.norm_type{opt.sel_norm}); 
ylabel('Density','fontsize',17,'interpreter','latex')
xlabel('$\hat{e}$','fontsize',17,'interpreter','latex')
title(['$\sigma^{2}$ = ',num2str(par.variance_e(1)),'  $\hat{\sigma}^{2}$ = ',num2str(var(vars_1.e_hat))],'interpreter','latex','fontsize',17)
xlim([-1.6,1.6])
subplot(3,1,2)
hold on
grid on
histogram(vars_2.e_hat,par.num_bins,'Normalization',opt.norm_type{opt.sel_norm}); 
ylabel('Density','fontsize',17,'interpreter','latex')
xlabel('$\hat{e}$','fontsize',17,'interpreter','latex')
title(['$\sigma^{2}$ = ',num2str(par.variance_e(2)),'  $\hat{\sigma}^{2}$ = ',num2str(var(vars_2.e_hat))],'interpreter','latex','fontsize',17)
xlim([-1.6,1.6])
subplot(3,1,3)
hold on
grid on
histogram(vars_3.e_hat,par.num_bins,'Normalization',opt.norm_type{opt.sel_norm}); 
ylabel('Density','fontsize',17,'interpreter','latex')
xlabel('$\hat{e}$','fontsize',17,'interpreter','latex')
title(['$\sigma^{2}$ = ',num2str(par.variance_e(3)),'  $\hat{\sigma}^{2}$ = ',num2str(var(vars_3.e_hat))],'interpreter','latex','fontsize',17)
xlim([-3,3])

%% 
% *Activity 3: Understanding Collinearity* 
% 
% $y = \beta_{0} + \beta_{1} x_{1} + \beta_{2} x_{2} + \epsilon$  Where   $\,\,\,\epsilon\sim \mathcal{N}(0,\sigma^{2}_{\epsilon})$
%
% and $X = (x_{1}, x_{2})'$ where $X \sim \mathcal{N}(\mu,\Sigma)$ with $\Sigma = \left[\begin{array}{cc}\sigma^{2}_{x_{1}} & \rho\sigma_{x_{1}}\sigma_{x_{2}} \\ \rho\sigma_{x_{1}}\sigma_{x_{2}} & \sigma_{x_{2}}^{2} \end{array}\right]$
% 
% Some Parameters we can play with:
% 
% # Number of Samples
% # Variance of the error $\sigma^{2}_{\epsilon}$
% # Variance ofx $\sigma^{2}_{x_{1}}$
% # Correlation $\rho$ between $x_{1}$ and $x_{2}$

par.names = {'$\sigma^{2}_{\epsilon}$ ','$\sigma^{2}_{x_{1}}$ ','$\rho$ '};
% Data Generating process values:
grids.sigma_e  = [0.01,0.3,0.6,1,2.6,3];
grids.sigma_x1 = [0.01,0.1,0.8,1.6,2,2.5];
grids.rho      = [0,0.6,0.9,0.95,0.99,1];

% Default Values:


par.n  = 100;       % Sample size
par.ns = 1000;      % Number of Montecarlo Samples
% Simulate x
par.mean_x1 = 20;
par.mean_x2 = 27;
par.variance_x2 = 1.4;
% Model coefficients:
par.beta0 = 2;
par.beta1 = 0.3;
par.beta2 = 1.5;
% Simulate error
err = NaN(par.n,par.ns);
y   = NaN(par.n,par.ns);
X   = NaN(par.n,2,par.ns);
SE_beta_hat = NaN(par.ns,1);
beta1_hat   = NaN(par.ns,1);
mu_beta     = NaN(6,3);
mu_SEbeta   = NaN(6,3);
% Simulate Data Generating Process:
par. variance_e  = grids.sigma_e(2);
par. variance_x1 = grids.sigma_x1(3);
par. rho         = grids.rho(1);    
        

for i = 1:3    
    it = 0;
    for ii = 1:6
        % Defaults:
  
        if i ==1
            par.varianve_e = grids.sigma_e(ii);
            par.name_val = par.varianve_e;
        elseif i ==2
            par.variance_x1 = grids.sigma_x1(ii);
            par.name_val = par.variance_x1;
        elseif i ==3
            par.rho = grids.rho(ii);
            par.name_val = par.rho;
        end
        % Simulate the Correlated Variables
        
        par.big_sigma = [par.variance_x1,sqrt(par.variance_x1)*sqrt(par.variance_x2)*par.rho;sqrt(par.variance_x1)*sqrt(par.variance_x2)*par.rho,par.variance_x2];
        for oo = 1:par.ns 
            % Generate the data
            rng((i*100000)+(ii*10000)+oo)
            err(:,oo) = 0 + sqrt(par.variance_e).*randn(par.n,1); 
            X(:,:,oo) = mvnrnd([par.mean_x1,par.mean_x2],par.big_sigma,par.n);
            y(:,oo) = par.beta0 + par.beta1.*X(:,1,oo)+par.beta2.*X(:,2,oo) +err(:,oo);
            % Estimate OLS
            try 
                vars = ols_esti(y(:,oo),[ones(par.n,1) X(:,:,oo)]);
                SE_beta_hat(oo,1) = vars.SEbeta_hat(2);
                beta1_hat(oo,1)   = vars.beta_hat(2);
            catch
                if oo ==1
                disp('Perfect Colinearity, check your variables!')
                end
                SE_beta_hat = NaN(par.ns,1);
                beta1_hat   = NaN(par.ns,1);
            end
            % Extract Values

        end
        
        mu_beta(ii,i)   =  mean(beta1_hat);
        mu_SEbeta(ii,i) =  mean(SE_beta_hat);
        % Compute and save the mean of the OLS estimator 
        % Plot the Histograms
        if ii == 1|| ii == 3|| ii ==5
        it = it+1;
        figure(10+i)
        subplot(3,1,it)
        hold on
        histogram(beta1_hat,par.num_bins,'Normalization',opt.norm_type{opt.sel_norm});
        xline(par.beta1,'g-','linewidth',2)
        xline(mean(mu_beta(ii,i)),'r-','linewidth',2)
        ylabel('Density','fontsize',13,'interpreter','latex')
        xlabel('$\hat{\beta}$','fontsize',13,'interpreter','latex')
        title([par.names{i},' = ',num2str(par.name_val)],'interpreter','latex','fontsize',15)

        end
        par. variance_e  = grids.sigma_e(2);
        par. variance_x1 = grids.sigma_x1(3);
        par. rho         = grids.rho(1); 
    end
    
end

%%
% The consequences of collinearity

figure(33)
hold on
grid on
plot(grids.rho,mu_beta(:,3),'ko-','MarkerFaceColor','k','linewidth',1.2)
plot(grids.rho,mu_SEbeta(:,3),'mo-','MarkerFaceColor','m','linewidth',1.2)
yline(par.beta1,'r')
ylabel('$\beta_{1}$','interpreter','latex','fontsize',17)
xlabel('$\rho$','interpreter','latex','fontsize',17)
legend({'$E(\hat{\beta_{1}})$','$E(SEbeta_{1})$','$\beta_{1}$'},'interpreter','latex','location','best')
title('Consequences of Collinearity')

%%
% Consequences of not having enough variation for identification 

figure(32)
hold on
grid on
plot(grids.sigma_x1,mu_beta(:,2),'ko-','MarkerFaceColor','k','linewidth',1.2)
plot(grids.sigma_x1,mu_SEbeta(:,2),'mo-','MarkerFaceColor','m','linewidth',1.2)
yline(par.beta1,'r')
ylabel('$\beta_{1}$','interpreter','latex','fontsize',17)
xlabel('$\sigma^{2}_{x1}$','interpreter','latex','fontsize',17)
legend({'$E(\hat{\beta_{1}})$','$E(SEbeta_{1})$','$\beta_{1}$'},'interpreter','latex','location','best')
title('Consequences of Low Variance for Identification')

%%
% No consequences of having having a larger variance of the error

figure(31)
hold on
grid on
plot(grids.sigma_e,mu_beta(:,1),'ko-','MarkerFaceColor','k','linewidth',1.2)
plot(grids.sigma_e,mu_SEbeta(:,1),'mo-','MarkerFaceColor','m','linewidth',1.2)
yline(par.beta1,'r')
ylabel('$\beta_{1}$','interpreter','latex','fontsize',17)
xlabel('$\sigma^{2}_{\epsilon}$','interpreter','latex','fontsize',17)
legend({'$E(\hat{\beta_{1}})$','$E(SEbeta_{1})$','$\beta_{1}$'},'interpreter','latex','location','best')
title('No Consequence of Larger measurment error')




%%
%REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH-
% OLS 
function [vars] = ols_esti(y,X)
%{
This function computes the Least Squares Estimate
Input: 
y: Dependent Variable    (N,1)
X: Independent Variables (N,K)
Output: 
Many stuff you saw in class.

%}
[par.Nx,par.K] 	= size(X);   % N=no.obs; K=no.regressors
[par.Ny] 	= size(y,1); % 

if par.Ny~=par.Nx
    error('X and y do not have same length')    
end
I = rank(X'*X) == par.K;
if I ==0
    error('Not complete Rank, Perfect Colinearity') 
end
par.N = par.Nx; % Save number of regressots

vars.beta_hat  = X\y; 
% Coefficients:
vars.beta_hat_alt  = inv(X'*X)*(X'*y); 
% Predicted values:
vars.y_hat 	= X*vars.beta_hat; 
% Residuals:		 
vars.e_hat 	= y-X*vars.beta_hat; 	
% Total Variation of the dependent variable  	 
vars.SST 	= (y - mean(y))'*(y - mean(y));
% (SSE) Sum Squared Residuals 
vars.SSE	= vars.e_hat'*vars.e_hat;
% SSR/SST or "r-squared" is the ratio of the variation in y explained by the model and the total variation of y	 
vars.R2 	= 1 - (vars.SSE/vars.SST); 	 
% Adjusted "r-squared".
vars.R2A 	= 1 - (vars.SSE/(par.N-par.K))/(vars.SST/(par.N-1));   

vars.sigma2_hat = vars.SSE/(par.N-par.K); 

%Variance of estimator:
vars.var_covar  = vars.sigma2_hat*inv(X'*X); 
vars.SEbeta_hat = sqrt(diag(vars.var_covar));

end


##### SOURCE END #####
--></body></html>
